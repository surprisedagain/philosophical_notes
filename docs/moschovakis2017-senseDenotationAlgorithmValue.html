<!DOCTYPE html>
<html>
<head>
<!-- processed with vwformat -->
<link rel="Stylesheet" type="text/css" href="style.css">
<title>moschovakis2017-senseDenotationAlgorithmValue</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<body>

<p>
<span id="-article"></span><span class="tag" id="article"><a href="tag_index.html#article">article</a></span> <span id="-representation"></span><span class="tag" id="representation"><a href="tag_index.html#representation">representation</a></span> <br>
<span id="-agree1"></span><span class="tag" id="agree1"><a href="tag_index.html#agree1">agree1</a></span> <span id="-quality1"></span><span class="tag" id="quality1"><a href="tag_index.html#quality1">quality1</a></span> <span id="-influence2"></span><span class="tag" id="influence2"><a href="tag_index.html#influence2">influence2</a></span>
</p>
<div id="sense and denotation as algorithm and value"><h1 id="sense and denotation as algorithm and value" class="header"><a href="#sense and denotation as algorithm and value">sense and denotation as algorithm and value</a></h1></div>
<p>
<p class="smallnote"> <a href="../zz.texts/moschovakis2017-senseDenotationAlgorithmValue.pdf">moschovakis2017-senseDenotationAlgorithmValue.pdf</a>,
<a href="https://doi.org/10.1017/9781316718254.015">https://doi.org/10.1017/9781316718254.015</a> </p>
</p>

<div id="sense and denotation as algorithm and value-short"><h6 id="short" class="header"><a href="#sense and denotation as algorithm and value-short">short</a></h6></div>
<p>
The core suggestion is that sentence meanings are, or can be put into a
one-one mapping with, the members of a certain class of algorithms. The key
problem is that the suggested algorithms only reflect the logical structure
(overt FOL schema) and the extensions of the predicates in the associated
sentences. The result is that by the suggested standard, logically equivalent
sentences with different logical structures are judged to be not synonymous, and
sentences which can be changed to one another by the substitution of
co-extensive predicates (e.g. <q>There exists a cordate.</q> and <q>There exists
a renate.</q>) are judged to be synonymous.
</p>

<p>
<p class="smallnote"> Does contain an interesting suggestion for liars paradox and other issues of
self-reference, connecting truth gaps with non-terminating algorithms. </p>
</p>

<div id="sense and denotation as algorithm and value-related to"><h6 id="related to" class="header"><a href="#sense and denotation as algorithm and value-related to">related to</a></h6></div>
<p>
??programs_are_theories??, <a href="extensional.html">extensional</a>
</p>

<div id="summary"><h1 id="summary" class="header"><a href="#summary">summary</a></h1></div>
<p>
A sloppy approach to logical notation, and a combination of over-confidence
and a remarkably poor understanding of the philosophical issues concerning
synonymy, have led the author to fail to understand the problem of identifying
sentence meanings and hence believe that they have solved it.
</p>

<p>
The central claim (though it is unclear if the author realises this) is that if
we view sentences as expressing (/having as meanings) algorithms for determining
their truth value, then this will allow us to define sentence synonymy. Among
the proposed solution's chief faults, the easiest to identify is that it is
extensional. By the proposed standard <q>There exists a cordate</q> is
synonymous with <q>There exists a renate</q>. (Game over.)
</p>

<p>
Somewhat akin to a computational version of Tarski's truth definition. Just as
Tarski's definitions only define truth given the extension of each
predicate and reflect only the logical structure by which those predicates are
combined — So too the algorithms produced according to this papers methods (the
algorithms that are supposed to be statements meanings/intentions) only reflect
statements' overt logical structure (the FOL schema they instantiate) and are
composed of algorithms for determining if an object is in the extension of a
given predicate. For Tarski's purpose, which was explicitly to define a notion
of logical truth this was adequate.  But here, where we are concerned with
identifying intentions of statements (/providing a standard of sentence
synonymy) it is not.
</p>

<p>
Though it is somewhat concealed by technical details and the authors blithe
confidence, the paper claims that all and only pairs of statements that can be
produced from FOL schema by systematically replacing predicate placeholders with
extensionally equivalent predicates or by changing the order of conjuncts or
disjuncts (e.g. changing <q>A and B</q> to <q>B and A</q>) are synonymous. This
is wrong in both directions.
</p>

<p>
The basis for claiming that the algorithms associated with statements by the
papers proposed method are those statements meanings, is that they divide
synonyms more finely than logical equivalence. Many logically equivalent
statements are claimed to expressing different algorithms and hence not to be
synonyms. If you close your left eye and squint this can look kinda like a finer
distinction than extensional equivalence, hence the illusion that these is a
notion of synonymy. The author notes examples of this finer grade distinction
with eminent satisfaction:
</p>
<blockquote>
(fp. 6) as one might expect, (φ &amp; ψ) and (ψ &amp; φ) are intensionally
equivalent with the standard interpretation of &amp; but ¬¬φ has a more complex
intension than φ.
</blockquote>
<p>
A more humble mind might have been worried by the conclusion that <q>¬¬φ</q> and
<q>φ</q> aren't synonymous, but the author is blessedly free from such doubts.
It is usually thought that logically equivalent statements are synonymous since
they have the same truth conditions.
</p>

<p>
The suggested account of meanings amounts to a standard for dividing sentences
into equivalence classes by their (overt) logical structure (and the extensions
of their predicates - but leave that aside for the moment) that is finer than
logical equivalence. The only change to a sentence's logical structure that will
<span id="summary-not"></span><strong id="not">not</strong> move it from one equivalence class to another is reversing the order of
conjuncts or disjuncts. So equivalence classes (for this relationship) are
classes of statements that have the same overt logical structure apart from the
order of conjuncts and disjuncts. By the proposed standard all members of any
one equivalence class are synonymous.
</p>

<p>
There is no reason to treat this proposal as an account of synonymy, apart from
its interesting treatment of liar paradox and other supposed instances of
truth-value gaps. On the one hand it treats as synonymous statements that are
not (e.g. produced by substituting co-extensive but non-synonymous predicates
such as <q>cordate</q> and <q>renate</q>). On the other it treats logically
equivalent statements as non-synonymous. All conveyed with a kind of blithe
bewilderment at why everyone apart from the author found this simple problem of
sentence meaning so difficult to solve!
</p>

<div id="summary-the good idea"><h2 id="the good idea" class="header"><a href="#summary-the good idea">the good idea</a></h2></div>
<p>
The papers best and most interesting suggestion is that the liar's paradox (and
truth teller and <q>forms a falsehood when appemded to its own quotation</q>)
and others that are sometimes thought to give rise to truth value gaps are
somehow connected with non-terminating <q>algorithms</q>. (Yes, on some
technical definitions algorithms must always halt, but that is the least of our
problems.)
</p>

<p>
There may be something to this - suppose we had sentence meanings. Given a
string we can determine/compute the matching meaning. But in the case of these
truth-gap sentences the algorithm to determine the meaning (in the author's view
the algorithm that <em>is</em> the meaning) never halts.  The idea that there is
something akin between non-terminating algorithms and truth gaps - that truth
gaps are due to non-terminating algorithms.
</p>

<p>
In essence this is a debate about whether the mapping from sentences to meanings
must be recursively decidable. This suggestion may have something to it.
</p>

<div id="summary-key flaw"><h2 id="key flaw" class="header"><a href="#summary-key flaw">key flaw</a></h2></div>
<p>
Rather than identifying the meaning of a sentence with a set of possible worlds
(in which that sentence is true<span class="tooltip">*<span class="tooltiptext">Better a 2-tuple of sets of possible worlds, those in which it is true and those in which it is false</span></span>&zwj;) identify it as an algorithm for
determining whether that statement is true(/false)
<em>that gives the right answer in every possible world</em>. (This issue turned out
not to play as large a role as I first thought since the extensionalism means we
only need the right extension for our predicates in this world and not in every
possible world. It over-estimates the paper to bring up this issue.)
</p>

<p>
That last caveat appears to be the key. Taken in a strong sense, does one
need to get the right answer in possible worlds in which there are married
bachelors. (That we rule out such possible worlds, and that such ruling out is
not done by the <q>algorithms</q> on offer shows we are relying upon something
else to set the standard of synonymy.)
</p>

<p>
Trying to see how the author deals with this problem reveals a more pressing
issue. This is, at very best equivalent to a Tarski style definition of truth.
It defines an algorithm <em>given</em> the extension of the basic predicates it
contains (in just this one world!). How those basic predicates get their
extensions is itself never explained. This is why these algorithms are so
reminiscent of Quine's main method for determining validity(/inconsistency) of
quantificational schema (see <a href="moschovakis2017-senseDenotationAlgorithmValue.html#potential problem 2">#potential problem 2</a>). Like the Tarskian truth
definition it captures the contribution of the logical machinery to the truth of
whole sentences, but it takes the parts for granted. It is a standard for
identifying overt logical structure  - treating statements as <q>synonymous</q>
provided they have the same logical structure (apart from the order of conjuncts
and disjuncts) and the unstructured predicates occupying the same positions
within these structures have the same extension.
</p>

<p>
One particular manifestation of this lack, is that the suggestion on offer is
<span id="summary-key flaw-extensional"></span><strong id="extensional">extensional</strong>.  <em>Pace</em> the introductory example χ on fp2. <q>If we know nothing
about R and Q but their extensions, there is basically only one way to determine
the truth value of χ</q>. If we know nothing about R and Q but their extensions
we cannot tell if they are synonymous predicates, or merely co-extensive. Unless
we can make this distinction then the algorithm for determining the truth of
<q>(EEx) x is a cordate</q> is the same algorithm as for determining the truth
of <q>(EEx) x is a renate</q>. This problem is set in stone when the author 
latter explicitly enjoins us to <q>agree to view an m-ary relation on a set X as
a function which assigns a truth value to each m-tuple in X</q>. Functions which
are extensionally equivalent (in this case which map the same tuples to the same
truth values) are the same function! Not so, we learnt at both our mothers and
Quine's knees, for relations.
</p>

<div id="summary-notes taken while reading"><h2 id="notes taken while reading" class="header"><a href="#summary-notes taken while reading">notes taken while reading</a></h2></div>
<div id="summary-notes taken while reading-response after superficial skim"><h3 id="response after superficial skim" class="header"><a href="#summary-notes taken while reading-response after superficial skim">response after superficial skim</a></h3></div>
<p>
Yes of course there is a connection between senses and algorithms. Computer
programs, which the most platonic believer in propositions might take as
expressing algorithms (taken as mathematical idealisations) <em>are</em> (or are at
least mechanically translatable into) theories. (In particular, theories
concerning the input/output and internal states of computers. Theories that are
true of the machines running those programs.)
</p>

<p>
Thus that algorithms are or are equivalent to senses in some way is not
surprising since algorithms are(/are expressed by) computer programs and
computer programs are theories and theories are paradigmatic sense
bearing/expressing objects. (Indeed for semantic holists they are <em>the</em> 
fundamental bearers of content, with other objects such as sentences deriving
their content from their role in such theories.)
</p>

<p>
<span id="summary-notes taken while reading-response after superficial skim-However"></span><strong id="However">However</strong>, algorithms are subject to the same indeterminacy as
theories/languages. Indeterminacy, at least on my view, is commonplace within
computer science, though it broader implications are poorly understood.
</p>

<p>
The way the author talks it suggests that he thinks the algorithm specified by a
program is perfectly determinate, or equivalently, that our talk of algorithms
as objects (presumably sets of some kind, perhaps Turing machine programs) is
not itself subject to the indeterminacy of translation. This is how one
initially suspects that the illusion of providing a sense for sentences will
proceed.
</p>

<p>
But there is worse, at least on my view, for it is whole theories that are
analogous (or rather equivalent) to programs/algorithms. Individual statements
are elements of theories. For just as we don't have access to the internal
states of computers but only their input/output under normal circumstances, so
to we don't have access to the truth of individual sentences, but only the
predictions(/retrodictions) implied by the whole theories of which they are
parts. This is why some translations from a language to itself can map sentences
held true (by the original speaker whose utterances are being thus translated)
onto sentences held false.
</p>

<p>
Thus there seem to be two problems. (1) The analogy is really between algorithms
and whole theories not algorithms and individual sentences (2) the algorithm
expressed by a program is indeterminate - good compilation, like other forms of
good translation preserves input/output conditions but not the <q>meanings</q>
of individual statements.
</p>

<div id="summary-notes taken while reading-notes on first reading by section"><h3 id="notes on first reading by section" class="header"><a href="#summary-notes taken while reading-notes on first reading by section">notes on first reading by section</a></h3></div>
<div id="summary-notes taken while reading-notes on first reading by section-introduction"><h4 id="introduction" class="header"><a href="#summary-notes taken while reading-notes on first reading by section-introduction">introduction</a></h4></div>
<blockquote>
To explain the basic idea, consider a typical sentence of predicate logic like
the arithmetical sentences above, but simpler: <br>
χ ≡ (∀x)(∃y)R(x, y) ∨ (∃z)Q(z). (4) <br>
Here R and Q are interpreted by relations R, Q on some domain A and we may
suppose at first, for simplicity that A is finite. If we know nothing about
R and Q but their extensions, there is basically only one way to determine
the truth value of χ, by the following procedure.
</blockquote>
<p>
the follows an <q>algorithm</q> (for loop) for checking each c ∈ Domain to see
if Q(c) (right hand side of disjunct) and a nested loop for checking the left
hand side of the disjunct.
</p>

<div id="summary-notes taken while reading-notes on first reading by section-introduction-potential problem 1"><h5 id="potential problem 1" class="header"><a href="#summary-notes taken while reading-notes on first reading by section-introduction-potential problem 1">potential problem 1</a></h5></div>
<p>
But of course, one never does <q>know nothing about R and Q but their
extensions</q> or in the extreme case where the objects that R and Q are true of
are given by enumeration, one doesn't check for each object in Domain to see if
it is on the list of Rs or Qs. Consider the way in which one proves Fermat's
last theorem - it is not the algorithm that consists of checking each triple of
natural numbers. To select one of these methods of determining the truth as
<q>the correct algorithm</q> (which captures/expresses/mimics the sense of the
sentence in question) seems problematic.
</p>

<p>
This problem develops into an extensional standard of synonymy.
</p>

<div id="summary-notes taken while reading-notes on first reading by section-introduction-potential problem 2"><h5 id="potential problem 2" class="header"><a href="#summary-notes taken while reading-notes on first reading by section-introduction-potential problem 2">potential problem 2</a></h5></div>
<p>
Algorithms described in this paper are reminiscent of Quine's main method for
proving quantificational schema to be inconsistent(/valid - prove S valid by
proving ~S inconsistent) in <a href="https://n2t.net/ark:/13960/s20gzfz2zbf"><cite>Methods of Logic</cite></a>.
Indeed the conditional of the existentially quantified (all constants replaced
with existentially quantified variables) counter example that would be found by
the specified algorithm as antecedent and χ as consequent, run through Quine's
main method would perform much the same operations. However, Quine's algorithm
makes no pretence at being decidable and so handles the infinite cases without
chicanery.
</p>

<p>
This seems like more a test of logical validity, rather than truth. How does
truth get into the picture - AH! only through the extensions of the fundamental
predicates! How that is determined is left out of the picture isn't it?
</p>

<p>
This problem develops into only grouping statements into equivalence classes (of
supposed <q>synonyms</q>) by their logical structure (and the extension of the
predicates that are thus combined). Logically equivalent sentences with
different logical structure will turn out not to by synonyms by this standard.
</p>

<div id="summary-notes taken while reading-notes on first reading by section-introduction-potential problem 3"><h5 id="potential problem 3" class="header"><a href="#summary-notes taken while reading-notes on first reading by section-introduction-potential problem 3">potential problem 3</a></h5></div>
<p>
Which algorithm? Is the algorithm in which we do Step (2) of the given algorithm
before Step (4) different that the other algorithm. What about one in which the
loops are nested in the opposite order? (i.e. instead of for each <em>a</em> check each
<em>b</em> to see if R(<em>a</em>,<em>b</em>) ; for each <em>b</em> check each <em>a</em> to see if R(<em>a</em>, <em>b</em>)
</p>

<p>
If these are different algorithms then which one is the meaning of χ ? But that
seems silly. Perhaps all those algorithms are equivalent and it is the
equivalence class of them that is the meaning.  Is what is doing the heavy
lifting here the truth conditions of χ rather than the algorithm. That the
algorithm <q>encodes</q> or is sensitive to the meaning is the result of the
fact that. But it is those truth conditions (and not the method of determining
them) that are the <q>meanings</q> of the relevant sentences.
</p>

<p>
This is the most serious problem, but the paper doesn't even develop to a point
where it becomes manifest.
</p>

<div id="summary-notes taken while reading-notes on first reading by section-1.1 Algorithms are semantic objects"><h4 id="1.1 Algorithms are semantic objects" class="header"><a href="#summary-notes taken while reading-notes on first reading by section-1.1 Algorithms are semantic objects">1.1 Algorithms are semantic objects</a></h4></div>
<blockquote>
This is almost self evident, but we list it because there is some general
tendency in the literature to confuse algorithms with programs, like the
instructions above.
</blockquote>

<p>
Perhaps the motive for confusing algorithms with programs is that programs,
unlike algorithms, are well defined sequences of symbols. (In actual practice,
plain text files.) So long as one assumes that algorithms are programs than the
link between the two is fixed. But once that is abandoned then the question of
<em>which</em> algorithm a program expresses arises.
</p>

<p>
What is being assumed in this paper (in the other direction) is that
<span id="summary-notes taken while reading-notes on first reading by section-1.1 Algorithms are semantic objects-each program expresses a determinate algorithm"></span><strong id="each program expresses a determinate algorithm">each program expresses a determinate algorithm</strong>. (see <a href="moschovakis2017-senseDenotationAlgorithmValue.html#potential problem 3">#potential problem 3</a>)
</p>


<div id="summary-notes taken while reading-notes on first reading by section-1.2 Algorithms are relatively effective"><h4 id="1.2 Algorithms are relatively effective" class="header"><a href="#summary-notes taken while reading-notes on first reading by section-1.2 Algorithms are relatively effective">1.2 Algorithms are relatively effective</a></h4></div>
<p>
The author is apparently worried that we will dismiss his <q>algorithms</q> as
not being algorithms at all, since the traditional (computer science) textbook
definition of algorithm requires them to always halt. Hence they are prepared to
take it a as relatively effective - i.e. relative to the basic operation of
determining whether an existentially quantified statement is true. While this 
</p>

<p>
As I (admittedly vaguely) recall the <q>higher type recursion</q> is achieved
(or at least studied) by the use of oracle machines which decide (in one step as
it were) an undecidable (but enumerable) problem of the lower level of recursion.
E.g. the standard method of getting to the recursive level one step above
the level of Turing Machines is to allow the use of an oracle machine which
solves the halting problem. (At each level there will be a class of decidable
and a class of enumerable classes/languages/problems.)
</p>

<p>
More generally any algorithm is only an algorithm relative to its fundamental
operations. (Turing machines get around the problem of defining the acceptable
class of basic operations - the ones that are acceptable components of
algorithms -  by giving examples: a handful of operations [erase, write one of a
finite number of symbols, move one square to the left/right, change to one of a
finite number of states] which are intuitively effective/mechanical. By this
method the need to specify criteria for effective mechanical basic operations is
avoided.)
</p>

<p>
It is true that the algorithms are always relative to their basic
operations (and methods of combining them which is where the recursive comes in
to recursive procedure/method) and one may take <q>determine the truth of an
existentially quantified statement</q> to be a basic operation.
</p>

<p>
Just as to assume that there is an oracle for determining whether or not a
turning machine halts is <span id="summary-notes taken while reading-notes on first reading by section-1.2 Algorithms are relatively effective-not"></span><strong id="not">not</strong> to provide an algorithm for determining whether
a TM halts; so too to assume there is an oracle for determining the truth of
existentially quantified statements (or parse tree therof, or partially
evaluated statements, or whatever it is that the author thinks the operation
which corresponds to an existential quantifier has as its input) is <span id="summary-notes taken while reading-notes on first reading by section-1.2 Algorithms are relatively effective-not"></span><strong id="not">not</strong> to
provide an algorithm for evaluating existential quantifiers but <span id="summary-notes taken while reading-notes on first reading by section-1.2 Algorithms are relatively effective-to give up"></span><strong id="to give up">to give up</strong> on
attempting to do so.
</p>


<div id="summary-notes taken while reading-notes on first reading by section-1.3 self-referential sentences"><h4 id="1.3 self-referential sentences" class="header"><a href="#summary-notes taken while reading-notes on first reading by section-1.3 self-referential sentences">1.3 self-referential sentences</a></h4></div>
<p>
So on this view self-referential sentences express <q>divergent</q> i.e. non
halting algorithms.
</p>

<p>
Yes I once thought that you could side-step the halting problem by claiming that
only halting programs were meaningful. That the meaning of a program was the
input-outputs it generated/accepted (much as in Quine's account of meaning the
meaning of a theory is the empirical evidence that con/infirms it) and hence
programs that did not halt (on any input? some?) did not express anything
meaningful at all.
</p>


<div id="summary-notes taken while reading-notes on first reading by section-1.5 Faithful translation"><h4 id="1.5 Faithful translation" class="header"><a href="#summary-notes taken while reading-notes on first reading by section-1.5 Faithful translation">1.5 Faithful translation</a></h4></div>
<p>
Have we fallen so far that the idea that the meaning of a sentence as its truth
conditions can be treated as a novelty?
</p>

<p>
Still, there is one way putting this, instead of identifying the meaning of a
sentence with the set of possible worlds of which is is true, treat it as an
algorithm for determining its truth (that gives the right answer in every
possible world). But then we would need to have the algorithm work in every
possible world and nothing is said in this paper to address this.
</p>


<div id="summary-notes taken while reading-notes on first reading by section-1.7 Sense Identity"><h4 id="1.7 Sense Identity" class="header"><a href="#summary-notes taken while reading-notes on first reading by section-1.7 Sense Identity">1.7 Sense Identity</a></h4></div>
<p>
This is the key claim - that we can define synonymy in terms of the identity of
these algorithms.
</p>

<p>
<q>A &amp; B</q> and <q>B &amp; A</q> are <q>intentionally equivalent</q> but
<q>~~A</q> <q>has a more complex intension</q> than <q>A</q>. Does this mean
that <q>A</q> and <q>~~A</q> are not synonymous by the proposed standard?
</p>
 

<div id="summary-notes taken while reading-notes on first reading by section-2"><h4 id="2" class="header"><a href="#summary-notes taken while reading-notes on first reading by section-2">2</a></h4></div>
<p>
ok - by now we have a sense of the key defect (its algorithms only reflect the
logical structure of sentences, not the <q>meanings</q> of their predicates they
contain, and hence does not distinguish co-extensive from synonymous
predicates). Lets look to see if we can find where this manifests itself in the
technical details:
</p>
<blockquote>
we first add to the basic vocabulary an infinite sequence Pk1 , Pk2 , . . .
of formal k-ary partial relation variables, for each k ≥ 0. The number k is
the arity of Pki .
</blockquote>
<p>
ok so the language may well be unlearnable - we have an infinite (uncountable)
number of basic predicates. Not sure relevant but still noteworthy. 
</p>

<div id="summary-notes taken while reading-notes on first reading by section-2-2.2"><h5 id="2.2" class="header"><a href="#summary-notes taken while reading-notes on first reading by section-2-2.2">2.2</a></h5></div>
<p>
First paragraph: (rough quote) If these things are variables then the string
(14) is a formula.
</p>

<p>
it just doesn't look like the author actually wants to claim that (14) is a
formula of LPCR. (14) has tri-bar, <q>&thickapprox;</q> and other symbols that were never
seen before. This <em>could</em> be treated as introducing these symbols into the
langauge, but I suspect the author only wants to introduce the symbols
<q>where</q> <q>{</q>, <q>}</q> and <q>&thickapprox;</q>.
</p>

<p>
Hence for instance when the author writes:
</p>
<blockquote>
the formal LPCR versions of the direct liar and truthteller intended by (6)
and (7) are: <br>
<em>liar</em> ≡ P() where {P() &thickapprox; ¬P()},
</blockquote>
<p>
I suspect the author does not wish to claim that <q><em>liar</em></q> is a token that
occurs to the left of tribar in some well formed formulae of LPCR. I suspect the
author wishes to say:
</p>
<blockquote>
the formal LPCR version of the diretc liar paradox is expressed by: <br>
P() where {P() &thickapprox; ¬P()}
</blockquote>

<p>
Although this can be viewed as a slip between use and mention it is not
critical, but it bodes ill. Sloppy technical details are going to provide cover
for the fundamental problems.
</p>

<p>
Even if we have got this as a formula, however, we have no way of determining
its truth value. In particular we have not determined which pairs of objects
<q>&thickapprox;</q> is true of.
</p>

<div id="summary-notes taken while reading-notes on first reading by section-2-2.3 PARTIAL FUNCTIONS"><h5 id="2.3 PARTIAL FUNCTIONS" class="header"><a href="#summary-notes taken while reading-notes on first reading by section-2-2.3 PARTIAL FUNCTIONS">2.3 PARTIAL FUNCTIONS</a></h5></div>
<blockquote>
Let us first agree to view an m-ary relation on a set X as a function which
assigns a truth value to each m-tuple in X. 
</blockquote>
<p>
And there we have it ladies and gentlemen, relations are functions which are
identified extensionally, therefore <q>cordate</q> is synonymous with <q>renate</q>, the
problem of synonymy is solved (and all true statements are necessarily true).
</p>

<p>
fp. 10 still using <q>&thickapprox;</q> without having defined it yet
</p>

<p>
the only hint we got was the paraphrase back in 2.2
</p>
<blockquote>
&hellip; {P(x)≃¬P(x)} &hellip; (16)<br>
&hellip; asserts that the relationship which is always equivalent to its
negation&hellip;
</blockquote>
<p>
perhaps this is why the definition of <q>&thickapprox;</q> is so conspicuous by its absence
it assumes a relationship of equivalence (synonymy equivalent) between
relationships.
</p>

<div id="summary-notes taken while reading-notes on first reading by section-2-2.4"><h5 id="2.4" class="header"><a href="#summary-notes taken while reading-notes on first reading by section-2-2.4">2.4</a></h5></div>
<p>
from bad to worse, now the meanings of <q>=, ¬, ∀, etc.</q> are included in the
structures tuple without further ado. What is the object that is the meaning of
<q>∀</q>, that in can be included in this tuple?
</p>

<p>
use vs mention has now turned to reification - since <q>∀</q> is meaningful
there must be some thing that is it meaning. Tedious.
</p>

<div id="summary-notes taken while reading-notes on first reading by section-2-2.7"><h5 id="2.7" class="header"><a href="#summary-notes taken while reading-notes on first reading by section-2-2.7">2.7</a></h5></div>
<blockquote>
φ : I am a child of Euclid or the child of a descendant of Euclid,<br>
ψ : Euclid is my parent or the parent of an ancestor of mine.<br>
</blockquote>

<p>
The point at which the author decides these two statements are not synonymous is
the point at which I decide its ok to stop reading any further.
</p>

<div id="summary-notes taken while reading-notes on first reading by section-2-3"><h5 id="3" class="header"><a href="#summary-notes taken while reading-notes on first reading by section-2-3">3</a></h5></div>
<p>
Oh but here we get into some bad philosophy about programs and algorithms.  If
the rest of the paper was better (i.e. the proposed standard of synonymy was
remotely plausible) then this stuff would become relevant.
</p>
<blockquote>
(fp. 17) The distinction between an algorithm f and the object f computed by
that algorithm—typically a function—is well understood. Consider, for
example the need to alphabetize (sort) a list of words in some alphabet
which comes up in a myriad of computing applications, from compilers of
programming languages to sophisticated word processing programs. There are
hundreds of known sorting algorithms and the study of their properties is a
sizable cottage industry straddling theoretical and applied computer
science: they all compute the same sorting function which assigns to every
list of words its ordered version.
</blockquote>

<p>
Well the difference between a program and the input-output sequences it
generates is fairly well understood, at least we understand that two programs
can generate the same input-output and yet be different programs.
</p>

<p>
We can, given a fixed range of basic operations say what it is for two
algorithms to be identical. Two algorithms are identical is for each input the
same sequence of basic operations is performed (and hence of course the same
output will be generated). But free of that range of basic operations its not
really clear what an algorithm is at all.
</p>
<blockquote>
Equally clear is the difference between an algorithm and its various
implementations in specific machines or the programs which express it in
specific programming languages. It is true that this distinction is
sometimes denied by computer scientists who take a formalist or nominalist
position towards the foundations of computing and recognize nothing but
programs, their syntactic properties and the “symbolic computations” they
define. Yet I have never known a programmer who did not know the difference
between “programming the mergesort algorithm in LISP” (a relatively trivial
task) and programming the mergesort in some assembly language, a notoriously
difficult exercise in introductory programming courses. What can the last
quoted sentence possibly mean if there is no such thing as “the mergesort
algorithm?”
</blockquote>

<p>
What can <q>he told the same story she did</q> possibly <em>mean</em> if there are no
such things as stories (and they are distinct from the letter by letter [or
phoneme by phoneme] sequences of symbols that express them). Oh if only life
were so easy! (What can they mean they did it for the sake of love, if there is
no such thing as the sake of love? Who said philosophy was hard.)
</p>

<p>
If the author really developed this point they might discover that the mapping
from programs to algorithms is indeterminate - just like compilation is - and
would then have re-discovered the indeterminacy of translation.
</p>

</body>
</html>
